---
title: Logbook for analysis of SCT and twin language data
author: Dorothy Bishop
date: started August 2018
output: html_document
---
NB Need to remove ASD/low IQ from language calculations - though could retain in beeswarm?


`r Sys.time()`

```{r load_packages, include = FALSE}
#################################################################################
#devtools::install_github("rubenarslan/formr")
require(formr) #to handle conflicts with 'select' function in dplyr (may not be needed)
library(tidyverse)
library(reshape2)  #for melt
library(knitr) #for kable - allows nice tables in Word output - but can be temperamental
library(gridExtra)
library(grid)
library(Hmisc)
library(doBy)
library(lme4) #linear model
library(lmerTest) #Adding this extra package provides p-values (if you want them) for your fixed effects.
library(ggridges) #for joyplot
library(car)
require(psych)
library(beeswarm) #particular plot type
library(beanplot) #ditto
library(yarrr) #for pirate plot - another plot type
library(lavaan) #for SEM to extract language factor
library(semPlot) #used with Lavaan
library(standardize)
library(ggpubr)
library(reshape2)
library(ggcorrplot)

#################################################################################

```


Need to create a main analysis file in which we have a code that corresponds to group.
Have col for trisomy which corresponds to XXX, XXY, XYY, and NA: NA will be twins
Makes sense to use randomtwininclude to select just one from each pair
For trisomies, have a col that specifies whether highbias or lowbias

Have a col that determines if meeting criteria for DLD - regardless of whether twin or not.
This can be same criterion as for doppler paper : this was:
<i>Results from the language/cognitive test battery were used to categorise children as having DLD if they scored more than 1 SD below population norms on two or more out of 13 language/literacy measures, and as TD if they scored below this threshold on no more than one measure. In previous studies, we have excluded children who met this criterion solely on literacy measures (TOWRE and NARA-II); 
Children were excluded from the sample if they met any of the following criteria: WASI nonverbal ability (performance IQ) more than two SDs below the population mean; diagnosis of autism spectrum disorder (ASD) in one or both twins; sensorineural hearing loss or failure of a hearing test on the day of testing; and brain injury or a serious medical condition affecting one or both twins.</i>

nb index of multiple deprivation from postcode (English)
http://imd-by-postcode.opendatacommunities.org/

Also see re: CCC-2 nonresponse rates - https://www.aapor.org/About-Us/History/Presidential-Addresses/2004-Presidential-Address.aspx

## Step 1
Read in latest SCT from redcap.
Do the same for the twins.
Select variables to be used.


```{r readredcap}
#########################################################################################
#redcap.dir <-"c:/Users/pthompson/Dropbox/project SCT analysis/Data from Redcap/"
redcap.dir <-"~/Dropbox/ERCadvanced/project SCT analysis/Data from Redcap/"

#Use latest version - now includes milestones
sct.redcap <- 'SCTDATA_DATA_2018-08-13_1234.csv'
#updated to include code indicating whether participated in prior study
twin.redcap <- 'TwinsData_DATA_2018-08-19_1139.csv' #updated to include ccc2_consistent variable
#also now has pheno_include, which selects individual twins for inclusion
sct.data <- read.csv(paste0(redcap.dir,sct.redcap),stringsAsFactors = FALSE)
twin.data <- read.csv(paste0(redcap.dir,twin.redcap),stringsAsFactors = FALSE)
names(sct.data)[1]<-"record_id"
names(twin.data)[1]<-"record_id"
#fix any columns with discrepant names
w<-which(colnames(twin.data)=='neurodev_diagnosis')
colnames(twin.data)[w] <-'neurodev_diag'
#Nb Coded so if you subtract 1 you get N older sibs: disregards birth order of twins
w<-which(colnames(sct.data)=='position_in_family')
colnames(sct.data)[w] <-'fam_position'

twin.data$dyslexia<-twin.data$dld_rd%%10 #modulus 10 , ie last digit
twin.data$lang_disorder<-round((twin.data$dld_rd-4.5)/10) #first digit is dld code

#add gender info to sct data so it merges properly
sct.data$female<-0
w<-which(sct.data$trisomy==1)
sct.data$female[w]<-1

sct.data$fam_id<-NA #dummy column to ensure merges ok
#########################################################################################
#----------------------------------------------------------------------------------
```

#Select data for short file
NB see SCT_twin_langpheno_orig.Rmd for script re creation of oromotor_ss_2.
Basically, we took the TD twins as norms, and used regression of raw score on Age to create residualised scaled scores

myintercept<-summary(mymod)$coefficients[1,1] gave value of 35.754
myb<-summary(mymod)$coefficients[2,1] gave value of 0.07612
myse<-summary(mymod)$sigma gave value of 9.1667
Then formula is:

z.oro<-100+15*(langcog$Oromotor_raw-(myintercept+langcog$Age*myb))/myse

The original script was tweaked on 19/8/18 to add values of oromotor_ss_2 for the 2nd twin.



```{r colselect}
#########################################################################################
#Specify columns to retain that are common to both sct and twin
#NB we are using oromotor_ss2, which is renormed against the TD twin group
keepcols <- c('record_id','fam_id','female','age_at_test','partial_testing','pass_hearing','wasi_matrices_ss','wasi_block_design_ss','wasi_vocab_ss','wdck_jhsn_ss',
              'sent_rep_ss','nonword_rep_ss','oromotor_ss_2','nara_acc_ss',      'nara_comp_ss','nara_rate_ss','towre_words_ss','towre_nonwords_ss','phab_pic_ss','phab_digit_ss','srs_t_score','slt','splang_conc','schooling','piq','neurodev_diag','dyslexia','lang_disorder',
              'hyperkinetic_icd_r1','adhd_comb_dsm_r1','adhd_hyp_dsm_r1','adhd_inatt_dsm_r1',
              'conduct_dsm_r1','asd_dsm_r1','autism_icd_r1','srs_t_score',
              'gcc','scdi','ccc_a','ccc_b','ccc_c','ccc_d','ccc_e','ccc_f',
              'ccc_g','ccc_h','ccc_i','ccc_j','ccc2_consistent','mo_educ','fa_educ','deprivation_index','fam_structure','fam_position','wordcode','sentcode','walkcode','drycode',
              'nepsy_oromotor_seq_raw')

twin.short <- select(twin.data,keepcols)
sct.short <- select(sct.data,keepcols) #NB 'select' is ambiguous between packages but should work ok if we use formr (otherwise need dplyr::select)
#########################################################################################

```

```{r wrangledata}
#----------------------------------------------------------------------------------

#Add columns that are specific to twins or SCTs so all aligned
sct.short$randomtwininclude <- 0 #this specifies child is not a twin but a trisomy
sct.short$zygosity <- NA
twin.short$randomtwininclude <- twin.data$randomtwininclude+1 #twins subdivided
#randomly into 1 and 2 for replication sample
twin.short$zygosity <- twin.data$zygosity
#2 ASD, 3 ASDsib, 4 fail hearing screen (35dB plus mean for better ear), 5 other (rare condition)
#The previous include variable was used for Doppler paper and had more stringent hearing criteria.

sct.short$trisomy <- sct.data$trisomy
sct.short$pre_postnatal_diag <- sct.data$pre_postnatal_diag
sct.short$why_tested <-sct.data$why_tested
sct.short$orig_famcode<-0
sct.short$orig_famcode[sct.data$orig_famcode>0]<-1 #if seen before this is 1
twin.short$trisomy <- NA
twin.short$pre_postnatal_diag <- NA
twin.short$why_tested <- NA
twin.short$orig_famcode<-NA
twin.short$splang_conc<-twin.data$splang_conc
sct.short$splang_conc<-NA
sct.short$pheno_include<-1
twin.short$pheno_include<-twin.data$pheno_include #this codes reason for exclusion as:
#2 ASD, 3 ASD-sib, 4-hearing, 5- other
#----------------------------------------------------------------------------------
#Bolt SCT and twin files together
all.short <-rbind(sct.short,twin.short)

#remove case of isochromosome
w<-which(all.short$trisomy==9)
all.short<-all.short[-w,]

all.short<-all.short[all.short$pheno_include==1,] #removes those with ASD, ASD-sib,hearing, other

#rename age variable
w<-which(colnames(all.short)=='age_at_test')
colnames(all.short)[w]<-'Age'

#add a column identifying age range: 1 = <6, 2 = 6-11;11, 3 = 12+
all.short$ageband<-2
w<-which(all.short$Age<72)
all.short$ageband[w]<-1
w<-which(all.short$Age>143)
all.short$ageband[w]<-3

#########################################################################################
```

##Step 2
#Deal with missing data
Codes are

999 – test not given

998 – result not valid (maladministration)

997 – result not valid (child refusal etc.)

996 – child too old/young for norms

Check for nonword rep - in some cases OK to substitute low score, if child unable to attempt task. 
```{r missingcheck}

all.short$pass_hearing[all.short$pass_hearing==9]<-NA #change 9 to NA for pass_hearing
#NB these include both refusal and equipment failure

#missing data has codes of 996-999 for language tests
w <- which(all.short$nonword_rep_ss>900)
print('Cases with missing nonword rep data: ')
all.short$record_id[w]
#These cases all checked : all SCT cases who either were not tested because v limited spoken language, or who refused spoken tests or had low scores on other language tests. All these cases assigned a scaled score of 3.
all.short$nonword_rep_ss[w] <- 3

#999 is code where child was not tested bcs too low-functioning
w <- which(all.short$wasi_vocab_ss==999)
print('Cases with missing Vocab data (999) reassigned to floor: ')
all.short$record_id[w]
#These assigned SS of 2.33 SD below mean (equivalent to 3 on NEPSY scale)
all.short$wasi_vocab_ss[w] <- 25

w <- which(all.short$wdck_jhsn_ss==999)
print('Cases with missing Woodcock_J data (999) reassigned to floor: ')
all.short$record_id[w]
#These assigned SS of 2.33 SD below mean (equivalent to 3 on NEPSY scale)
all.short$wdck_jhsn_ss[w] <- 55

w <- which(all.short$sent_rep_ss==999)
print('Cases with missing Sent rep data (999) reassigned to floor:: ')
all.short$record_id[w]
#These assigned SS of 2.33 SD below mean (equivalent to 3 on NEPSY scale)
all.short$sent_rep_ss[w] <- 3

w <- which(all.short$oromotor_ss_2==999)
print('Cases with missing oromotor data (999) reassigned to floor:: ')
all.short$record_id[w]
#These assigned SS of 55 , as this corresponds to floor in this sample
all.short$oromotor_ss_2[w] <- 55

#Now count how many tests have missing data
mycols<-colnames(all.short)
#Identify the range of columns where 900+ is missing data code
mc <-which(mycols=='wasi_matrices_ss')
mc0<-which(mycols=='nonword_rep_ss') #end of range for spoken language
mc1<-which(mycols=='phab_digit_ss') #end of range of reading related
mc2<-which(mycols=='ccc_a') #end of range of reading related
mc3<-which(mycols=='ccc_j') #end of range of reading related

all.short$nmissinglang<-0
for(i in 1:nrow(all.short)){
  mytests<-all.short[i,mc:mc0]
 nna<- length(which(is.na(mytests)))
 n9<- length(which(mytests>900))
  all.short$nmissinglang[i]<-(nna+n9)
  
}
table(all.short$nmissinglang,all.short$ageband)

all.short$nmissingread<-0
for(i in 1:nrow(all.short)){
  mytests<-all.short[i,(mc0+1):mc1]
   nna<- length(which(is.na(mytests)))
 n9<- length(which(mytests>900))
  all.short$nmissingread[i]<-(nna+n9)
  
}
table(all.short$nmissingread,all.short$ageband)


#Put in NA for missing data codes all lang/read/CCC-2
for (i in c(mc:mc1,mc2:mc3)){
  w <- which(all.short[,i]>900)
  all.short[w,i]<-NA
  
  ncol<-length(colnames(all.short)) #define ncol here
  
}

#Parental educ variables, missing is 9
w<-which(all.short$mo_educ==9)
all.short$mo_educ[w]<-NA
w<-which(all.short$fa_educ==9)
all.short$fa_educ[w]<-NA


```
Rescale all variables to mean 100 and SD 15 and save in new columns

```{r rescalelang}
shortlangnames<-c('Matrices','Blocks','Vocab','Comprehnsn','SentRep','NwdRep','Oromotor',
                  'ReadAcc','ReadComp','ReadRate','TOWREwd','TOWREnwd',
                  'PicName','DigitName')

#convert all variables to same scale: mean 100 and SD 15
#This has to be hard coded because different tests on different scales
langcogcols<-c("wasi_matrices_ss" ,"wasi_block_design_ss", "wasi_vocab_ss" ,
               "wdck_jhsn_ss" , "sent_rep_ss" , "nonword_rep_ss",  "oromotor_ss_2",
               "nara_acc_ss" ,"nara_comp_ss","nara_rate_ss" ,"towre_words_ss",
               "towre_nonwords_ss","phab_pic_ss","phab_digit_ss")
#Note we now are using the oromotor_ss_2 variable: normed against TD twins

langcols<-which(colnames(all.short)%in%langcogcols)
#NB this finds columns corresponding to langcogcols, but they will be in the order they occur in file
#start by just duplicating original scaled scores
nnew<-length(shortlangnames)
nurange<-(ncol+1):(ncol+nnew) #column range for ss values, NB ncol defined in prev block
all.short[,nurange]<-all.short[,langcols]
colnames(all.short)[nurange]<-shortlangnames
#First 3 are normed with mean 50 and SD 10
for (i in 1:3){
  oldmean<-50
  oldsd<-10
  all.short[,(i+ncol)]<- 100+15*(all.short[,langcols[i]]-oldmean)/oldsd
}

for (i in c(5,6)){
  oldmean<-10
  oldsd<-3
  all.short[,(i+ncol)]<- 100+15*(all.short[,langcols[i]]-oldmean)/oldsd
}

```

```{r interpolatemissing}
#If just one value is missing in lang or reading groups, substitute the mean for others
langrange<-(ncol+1):(ncol+7)
readrange<-(ncol+8):(ncol+13)
#Start with language range
w<-which(all.short$nmissinglang==1) #find those rows with just one missing value
for(s in 1:length(w)){
  thisrow<-w[s] #row with missing value
  v<-which(is.na(all.short[thisrow,langrange])) #which value is missing?
  mycol<-langrange[v] #column with missing data
  all.short[thisrow,langrange[v]]<-round(rowMeans(all.short[thisrow,langrange],na.rm=TRUE),0) #mean of other values substituted
}

print(paste0('Interpolated ', length(w),' missing values from ',nrow(all.short)*length(langrange),
             ' datapoints in ',length(langrange),' nonverbal and language tests; cases with one missing datapoint, mean substituted'))

w<-which(all.short$nmissingread==1) #find those rows with just one missing value
for(s in 1:length(w)){
  thisrow<-w[s] #row with missing value
  v<-which(is.na(all.short[thisrow,readrange])) #which value is missing?
  mycol<-readrange[v]
  all.short[thisrow,readrange[v]]<-round(rowMeans(all.short[thisrow,readrange],na.rm=TRUE),0) #mean of other values substituted
}
print(paste0('Interpolated ', length(w),' missing values from ',nrow(all.short)*length(readrange),
             ' datapoints in ',length(readrange),' reading and rapidnaming tests; cases with one missing datapoint, mean substituted'))




```
## Step 3

#Check that Ns match those in the protocol
Should have three groups with N = 142 SCT, 194 twin1 and 194 twin2 (these are randomly assigned twin 1 and 2), - but Ns less for twins because of exclusions
Numbers are greater than for Newbury et al, as some children did not feature in that study because of lack of DNA.

Twins recruited in relation to splang_conc, which is coded as
0, never
1, preschool only
2, continuing, mild
3, continuing, severe
4, reading concerns only
9, unclear
We will be using this categorisation to subdivide twins; categories 2 and 3 distinguished.

Trisomies - divided according to reason for diagnosis
why tested used to make bias column: coded as: 
0, maternal age
1, medical concerns
2, behavioural concerns
3, neurodevelopmental concerns
4, family history of genetic problems
9, no information

```{r ncheck}
###################################################################################
twintab <- table(all.short$randomtwininclude)
names(twintab)<-c('SCT','twin1','twin2')

all.short$bias<-'NA'
w<-which(all.short$randomtwininclude==0)
all.short$bias[w]<-0
w<-c(which(all.short$why_tested==2),which(all.short$why_tested==3))
all.short$bias[w]<-1
scttab <- table(all.short$trisomy,all.short$bias)
rownames(scttab)<-c('XXX','XXY','XYY')
colnames(scttab)<-c('low bias','high bias','NA')
#Show tables
twintab
scttab
rowSums(scttab)

all.short$parentconc<-NA #parental concern re language
w<-which(all.short$randomtwininclude>0)
all.short$parentconc[w]<-0
w<-which(all.short$splang_conc%in%c(2,3))
all.short$parentconc[w]<-1

parcontab<-table(all.short$parentconc,all.short$randomtwininclude)
parcontab<-parcontab[,2:3]
rownames(parcontab)<-c('No concern','Concern')
colnames(parcontab)<-c('twin1','twin2')
parcontab
print('Age range (min, max, average) for SCT')
min(sct.data$age_at_test)
max(sct.data$age_at_test)
mean(sct.data$age_at_test)
print('Age range (min, max, average) for twin')
min(twin.data$age_at_test)
max(twin.data$age_at_test)
mean(twin.data$age_at_test)

#count how many SCT cases were in the earlier 2009 study (Bishop et al 2011 paper)
print('')
print('In 2009 study')
w<-which(all.short$orig_famcode==1)
origstudy<-table(all.short$bias[w],all.short$trisomy[w])
colnames(origstudy)<-c('XXX','XXY','XYY')
rownames(origstudy)<-c('Low bias','High bias')
origstudy

#Count how many cases available for MANOVAs
#Must have full data on lang or reading (5 yr olds excluded on this basis)
w<-which(all.short$nmissinglang<2) #we have retained those with one missing value
tempshort<-all.short[w,]
scttab <- table(tempshort$trisomy,tempshort$bias)
rownames(scttab)<-c('XXX','XXY','XYY')
colnames(scttab)<-c('low bias','high bias','NA')
#Show tables
print('Cases with full data for nv/lang analysis')

scttab
rowSums(scttab)

w<-which(all.short$nmissingread<2) #we have retained those with one missing value
tempshort<-all.short[w,]
scttab <- table(tempshort$trisomy,tempshort$bias)
rownames(scttab)<-c('XXX','XXY','XYY')
colnames(scttab)<-c('low bias','high bias','NA')
#Show tables
print('Cases with full data for reading/naming analysis')

scttab
rowSums(scttab)
###################################################################################
```


##Create 8 groups:
1. XXX-nobias
2. XXY-nobias
3. XYY-nobias
4. XXX-hibias
5. XXY-hibias
6. XYY-hibias
7. twin_noconcern
8. twin_concern
NB as currently defined, not taking into account co-twin status. So a twin_noconcern could have cotwin with concern, ie have family risk.

```{r groupcreate}
#####################################################################################
#first code SLT into 0, 1 or 2;  2 indicates SALT beyond 4 yr, 1 is assessment or preschool only
all.short$sltcode<-0
w<-c(which(all.short$slt==1),which(all.short$slt==8))
all.short$sltcode[w]<-1
w<-c(which(all.short$slt==2),which(all.short$slt==3))
all.short$sltcode[w]<-2


all.short<-filter(all.short,randomtwininclude<2) #remove twin2
all.short$group8<-all.short$trisomy
w<-which(all.short$bias==1)
all.short$group8[w]<-all.short$group8[w]+3 #convert 1 2 3 to 4 5 6
w<-which(all.short$randomtwininclude>0) #just focus on twins
all.short$group8[w]<-7
w<-which(all.short$parentconc==1) #coded as NA for SCTs, so only twins coded here
all.short$group8[w]<-8

#add twins with SLT code 2 to group 8, even if no parental concern
w<-intersect(which(all.short$group8==7),which(all.short$sltcode==2))
all.short$group8[w]<-8

#Tried removing those with affected cotwin, but it has little effect other than to reduce N.
#This is therefore not done at present, though code retained.
remove.by.cotwin<-0
if(remove.by.cotwin==1){
#now remove from group 7 those who have an affected cotwin: either SLT or concerns
cotwins<-filter(twin.short,randomtwininclude==2)
f<-which(all.short$group8==7)
cotwinremove<-vector()
for (i in 1:length(f)){
  thisrow<-f[i]
  thisfam<-all.short$fam_id[thisrow]
  g<-which(cotwins$fam_id==thisfam)
  thisslt<-cotwins$slt[g]
  thislangconcern<-cotwins$splang_conc[g]
  if(thisslt==2 || thisslt==3 || thislangconcern==2 ||thislangconcern==3)
  {cotwinremove<-c(cotwinremove,thisrow)}
}
all.short<-all.short[-cotwinremove,]
}

all.short$group8level<-all.short$group8#useful to retain numeric code before converting to factor
all.short$group8<-as.factor(all.short$group8)
levels(all.short$group8)<-c('XXX.lowbias','XXY.lowbias','XYY.lowbias',
                            'XXX.hibias','XXY.hibias','XYY.hibias',
                            'twin.TD','twin.langconcerns')

#Add code for thse with NA data on the language tests
#For MANOVA, only those with complete data are included
all.short$langdatacomplete<-1 #applied after interpolating values if only one missing
mycols<-colnames(all.short)
mcx1 <-which(mycols=='Matrices')
mcx2<-which(mycols=='DigitName')
for (i in mcx1:mcx2){
  w <- which(is.na(all.short[,i]))
  all.short$langdatacomplete[w]<-0
  
}

#Now recode all SCTs together in one group for contrast with twins
all.short$trisomyvstwin<-1
all.short$trisomyvstwin[all.short$group8level<7]<-2

```
##Covariates
a)	Educational level of mother and father, transformed into an ordinal scale based on age at leaving full-time education/qualifications obtained, with points of 0 (prior to age 16 years), 1 (16 years/did GCSE or O-levels), 2 (18 years/ did A-levels), 3 (21 years, degree), 4 (postgraduate study). 

b)	An index of multiple deprivation based on postcode was obtained for those living in England from the website http://imd-by-postcode.opendatacommunities.org/. This uses local statistics from the Department for Communities and Local Government to rank over 32,000 postcodes on the basis of a weighted sum based on income, employment, education, health, crime, housing and living environment. The rank score was converted to a z-score to give a normally-distributed variable.  

c)	Living with single parent, coded as a binary variable (0 or 1), based on status at the time of the initial interview.

d)	Number of older siblings. For twins, the co-twin was not counted.

N.B. The finding that the lowbias SCT children are more likely to have older sibs is probably related to the fact that pre-natal testing is associated with older parents. We do have data on parental ages and could look at that, but not sure it's necessary. It does, though, make me concerned that there may be problems in using N older sibs as a covariate, as it could look causal when it is not. It might be reasonable to use it just within the twin group.

```{r get.covariates}
#Parental educational level
par.ed <-aggregate(all.short$mo_educ, by=list(all.short$group8),
                   FUN=mean, na.rm=TRUE)
pirateplot(mo_educ~group8,data=all.short)
pirateplot(fa_educ~group8,data=all.short)

#Deprivation index
#pirateplot(deprivation_index~group8,data=all.short,main='Deprivation index: high is good')

#Can generate deciles, but better to normalise deprviation index as below
#depcut<-3275*c(1,2,3,4,5,6,7,8,9)
# print('Deprivation index decile cutpoints are:')
# print(depcut)
# pirateplot(deprivation_index~mo_educ,data=all.short,main='Deprivation index: high is good')

#Use ranks to convert to normal distribution
#Rw deprivation index is a rank out of 32750
all.short$deprivz<-qnorm(all.short$deprivation_index/32750)
w<-which(is.na(all.short$deprivz))
all.short$deprivz[w]<-0
#Assign zscore of zero to those outside england where no dep index

#NB rows below 143 are trisomies
print(paste('N SCT with missing dep index (assigned 0) = ',length(which(w<143))))
print(paste('N twin with missing dep index (assigned 0) = ',length(which(w>142))))
all.short$deprivz[w]<-0
pirateplot(deprivz~group8,data=all.short,xaxt='n')
text(1,3.2,'XXX',cex=.8)
text(2,3.2,'XXY',cex=.8)
text(3,3.2,'XYY',cex=.8)
text(4,3.2,'XXX',cex=.8)
text(5,3.2,'XXY',cex=.8)
text(6,3.2,'XYY',cex=.8)
text(7,3.4,'Twin\nno concerns',cex=.8)
text(8,3.2,'Twin\nlanguage\nproblems ',cex=.8)
text(2,-3,'<-------Low bias------->')
text(5,-3,'<-------High bias------->')
all.short$singlepar<-0
all.short$singlepar[all.short$fam_structure<3]<-1
singlepar.tab<-table(all.short$group8,all.short$singlepar)
colnames(singlepar.tab)<-c('2 parents','single parent')
prop.table(singlepar.tab,1)

print('N older siblings')
all.short$oldersibs<-all.short$fam_position-1
nsib.tab<-table(all.short$group8,all.short$oldersibs)
round(prop.table(nsib.tab,1),3)

ncol<-length(colnames(all.short)) #we will use this in later block as start column when adding new columns with all scaled on same scale
```
#Proportions meeting criteria for DLD
And proportions having SALT
Coded as: 
0 never
1 preschool
2 beyond 4 yr
3 ongoing
8 assessed only
9 no info

```{r DLDcategories}
#now recode according N language tests low
#use the language tests scaled to 100 (cutoff 85), exclude reading, include GCC (cutoff 55)
v<-which(colnames(all.short)=='Vocab')
g<-which(colnames(all.short)=='gcc')
all.short$Ntestlow<-0
all.short$Ntestdone<-6
for(i in 1:5){
  thiscol<-i+v-1
  w<-which(all.short[,thiscol]<85)
  all.short$Ntestlow[w]<-all.short$Ntestlow[w]+1
  w<-which(is.na(all.short[,thiscol]))
  all.short$Ntestdone[w]<-all.short$Ntestdone[w]-1
}
#now add gcc
  w<-which(all.short[,g]<55)
  all.short$Ntestlow[w]<-all.short$Ntestlow[w]+1
  w<-which(is.na(all.short[,g]))
  all.short$Ntestdone[w]<-all.short$Ntestdone[w]-1

  #table of whole range of low test
 lowtab<- table(all.short$group8,all.short$Ntestlow)
 round(prop.table(lowtab,1),2)
 
   #binarise Ntestlow into 0/1 and 2+
 all.short$dldcat<-0
 w<-which(all.short$Ntestlow>1)
 all.short$dldcat[w]<-1
 #need to also add exclusionary categories: lowIQ,Autism,Hearing
 w<-which(all.short$pass_hearing==0)
 all.short$dldcat[w]<-4
 
 #asd use rater 1 dsm5, DAWBA gives 1 unsure, 2 ASD, 3 Asperger and 4 other. We have used the 4 = other for cases such as SCD where only 2 domains are met
  w<-c(which(all.short$asd_dsm_r1==2),which(all.short$asd_dsm_r1==3)) #categories 2-3 treated as Asd
 all.short$dldcat[w]<-3
 #lowIQ
 w<-which(all.short$piq<70)
 all.short$dldcat[w]<-2
 
 all.short$dldlevel<-all.short$dldcat #retain numeric level for easy of filtering later
 
 all.short$dldcat<-as.factor(all.short$dldcat)
 levels(all.short$dldcat)<-c('TD','DLD','lowIQ','ASD','hearing')
 dldcat<-table(all.short$dldcat,all.short$group8)
 round(prop.table(dldcat,2),2)
 
round(table(all.short$dldcat,all.short$sltcode),2) #check how SALT relates to DLD status
```
##Analyse language test and reading data
First select the data 

Then make shorter sctfile that excludes the high bias group

```{r make.subfiles}
lobias.sct<-filter(all.short,group8level%in%c(1:3,8)) #we're using numeric code for factor level to make this easier
#exclude those with ASD, low IQ or hearing exclusion
lobias.sct<-filter(lobias.sct,dldlevel<2)

lobias.sct$Group<-as.factor(lobias.sct$group8level)
levels(lobias.sct$Group)<-c('XXX','XXY','XYY','Twin')

#exclude those with incomplete data as they won't feature in MANOVA
lobias.sct2<-filter(lobias.sct,langdatacomplete==1) 



#exclude those outside twin age band - this is a new file so we can compute medians for those separately
lobias.sct3<-filter(lobias.sct2,ageband==2)

twin.TD<-filter(all.short,group8level==7) #we're using numeric code for factor level to make this easier
twin.TD$Group<-'TD.twin'

trisomy.only<-filter(all.short,group8level<7) 

```

#Now do a grid of beeswarm plots

```{r beeswarmgrid}
longname<-c('Matrices','Block Design','Vocabulary','Comprehension','Sentence Repetition','Nonword Repetition','Oromotor',
            'Reading Accuracy','Reading Comprehension','Reading Rate','Speeded word reading','Speeded nonword reading',
            'Rapid Naming: Pictures','Rapid Naming: Digits')

png_lang_bees<-'beeswarm_lang.png' #name to save png file
png(png_lang_bees,width=1000,height=1000)
par(mfrow=c(5,3)) #5 row and 3 columns
par(mar=c(5.1,4.1,4.1,0.2))
#beeswarm jittered values (last value in jitter statement determines amount of jitter)

pointcol<-c(1,16,10) #use open circle, filled circle, circle +, for ageband 1-3
agebit<-pointcol[lobias.sct2$ageband]
#alldatabit<-pointcol[(1+lobias.sct$langdatacomplete)] #orig values are 0 and 1, so add 1
for (i in 1:14){
  mytitle<-longname[i]
  beeswarm(jitter(lobias.sct2[,nurange[i]],3)~Group , data = lobias.sct2, xlab='Group',ylab='Scaled score',spacing=.8,
           pch = 16,pwpch=agebit,cex=1.7,col=c(2,2,2,4),main=mytitle,ylim=c(55,135))
  bxplot(lobias.sct2[,nurange[i]]~Group , data = lobias.sct2, probs = 0.5, col = 1,lty=3,add=TRUE) #adds medians for all cases with dotted line
   bxplot(lobias.sct3[,nurange[i]]~Group , data = lobias.sct3, probs = 0.5, col = 1,add=TRUE) #adds medians just for those in Twin age range, with continuous line
  abline(a=100,b=0,col='darkgray',lty=1)
  abline(a=85,b=0,col='darkgray',lty=2)
  abline(a=70,b=0,col='darkgray',lty=2)
  
  mean_TD<-mean(twin.TD[,nurange[i]],na.rm=T)
  sd_TD<-sd(twin.TD[,nurange[i]],na.rm=T)
  
  up.lim<-mean_TD+sd_TD
  low.lim<-mean_TD-sd_TD
  
  polygon(c(0,0,5,5), c(up.lim, low.lim, low.lim, up.lim),
          col=adjustcolor("yellow",alpha.f=0.3), border = NA)
  
}
dev.off()
```
![Beeswarm plots](beeswarm_lang.png)




```{r lang.manova}
#First just do groups 1-3
#NB cases with missing data are excluded, so doesn't matter if you use lobias.sct or lobias.sct2
#Result will be the same, but use lobias.sct2 to get numbers to report
gp3<-filter(lobias.sct2,group8level<4)
sct.matrix <- as.matrix(gp3[,nurange])
gp3.fit <- manova(sct.matrix ~ gp3$Group+gp3$mo_educ+gp3$deprivz)
mymanova3<-summary(gp3.fit, test="Pillai")
print('Manova on the 14 language measures for the 3 Low Bias SCT groups only')
mytab<-table(gp3$trisomy)
names(mytab)<-c('XXX','XXY','XYY')
print('Ns for analysis:')
print(mytab)
mymanova3
#summary.aov(gp3.fit) - if you want to inspect individual language measures




#for comparison with twin group, need to restrict to those aged 6-11
w<-c(which(lobias.sct2$ageband==2))
lobias.agematch<-lobias.sct2[w,]
gp2.matrix <- as.matrix(lobias.agematch[,nurange])
gp2.fit <- manova(gp2.matrix ~ lobias.agematch$trisomyvstwin+lobias.agematch$mo_educ+lobias.agematch$deprivz)
mymanova2<-summary(gp2.fit, test="Pillai")
mytab<-table(lobias.agematch$trisomyvstwin)
names(mytab)<-c('Trisomy','Twin')
print('Ns for analysis:')
print(mytab)
print('Manova on the 14 language measures for the SCT vs twin (language disordered) group, aged 6-11;11')
mymanova2

#This plot not really adding anything, now we have coded age in the other beeswarm
png('png_2gp_bees.png',width=1000,height=1000)
par(mfrow=c(4,4)) #4 row and 4 columns
par(mar=c(5.1,4.1,4.1,0.2))
for (i in 1:14){
  mytitle<-longname[i]
  beeswarm(jitter(lobias.sct2[,nurange[i]],3)~trisomyvstwin , data = lobias.sct2, xlab='Group',ylab='Scaled score',
           pch = 16,cex=1,col=c(2,4),main=mytitle,ylim=c(50,140))
  bxplot(lobias.sct2[,nurange[i]]~trisomyvstwin , data = lobias.sct2, probs = 0.5, col = 1,add=TRUE) #adds medians
}
dev.off()

```
##Inspect correlations with heat map
Problems combining heatmaps into same plot?
These plots no longer needed, given that no group effect - previously, before excluding older SCT cases, there was a group effect, which seemed driven by different associations between reading/language measures. Can still see a suggestion of this - lighter red for lang/read correlations in twins. But as NS, not worth exploring further.

```{r heatmapcorr}
 png_heat<-'heat_plot_sct.png'
 png(png_heat,width=1000,height=500)
cormat_SCT <- round(cor(lobias.sct2[lobias.sct2$mycontrast==1,nurange],use="na.or.complete"),2)
ggcorrplot(cormat_SCT,title='SCT')
dev.off()
 png_heat<-'heat_plot_twin.png'
 png(png_heat,width=1000,height=500)
cormat_twin <- round(cor(lobias.sct2[lobias.sct2$mycontrast==8,nurange],use="na.or.complete"),2)
ggcorrplot(cormat_twin,title='Twin')
dev.off()
```
![Correlations: SCT age 6-11;11](heat_plot_sct.png)

![Correlations: Twin with lang dis](heat_plot_twin.png)
##Comparison of low and high bias groups

```{r lowhi.sct}
#Use trisomy.only group for this

png_lang_bees<-'beeswarm_lang_bias.png' #name to save png file
png(png_lang_bees,width=1000,height=1000)
par(mfrow=c(5,3)) #5 row and 3 columns
par(mar=c(5.1,4.1,4.1,0.2))
#beeswarm jittered values (last value in jitter statement determines amount of jitter)

pointcol<-c(1,16,10) #use open circle, filled circle, circle +, for ageband 1-3
agebit<-pointcol[trisomy.only$ageband]
#alldatabit<-pointcol[(1+lobias.sct$langdatacomplete)] #orig values are 0 and 1, so add 1
for (i in 1:14){
  mytitle<-longname[i]
  beeswarm(jitter(trisomy.only[,nurange[i]],3)~group8level , data = trisomy.only, xlab='Group',ylab='Scaled score',spacing=.8,labels='',
           pch = 16,pwpch=agebit,cex=1.7,col=c(2,2,2,1,1,1),main=mytitle,
           ylim=c(55,140))
  bxplot(trisomy.only[,nurange[i]]~group8, data = trisomy.only, probs = 0.5, 
         col = 1,lty=1,add=TRUE) #adds medians for all cases with dotted line
   abline(a=100,b=0,col='darkgray',lty=1)
  abline(a=85,b=0,col='darkgray',lty=2)
  abline(a=70,b=0,col='darkgray',lty=2)
  #same settings for polygon as before: shows TD twin range
  polygon(c(0,0,7,7), c(up.lim, low.lim, low.lim, up.lim),
          col=adjustcolor("yellow",alpha.f=0.3), border = NA)
  text(1,133,'XXX',cex=1)
text(2,133,'XXY',cex=1)
text(3,133,'XYY',cex=1)
text(4,133,'XXX',cex=1)
text(5,133,'XXY',cex=1)
text(6,133,'XYY',cex=1)
text(2,140,'<---------Low bias--------->')
text(5,140,'<---------High bias--------->')

}
dev.off()
```

```{r manova2}

sct2.matrix <- as.matrix(trisomy.only[,nurange])
gp6.fit <- manova(sct2.matrix ~ trisomy.only$bias*trisomy.only$group8+trisomy.only$mo_educ+trisomy.only$deprivz)
mymanova6<-summary(gp6.fit, test="Pillai")
print('Manova on the 14 language measures for the 3 Low Bias SCT groups vs 3 High Bias')
mytab<-table(trisomy.only$bias)

print('Ns for analysis:')
print(mytab)
mymanova6
summary.aov(gp6.fit) #- if you want to inspect individual language measures

```

##CCC-2 analysis
Consider how CCC-2 profiles for SCTs compare with those in our previous paper. Also include twins with concerns as comparison group.  Plot subscales; also analyse the GCC and SIDC.

```{r ccc2}
w<-which(colnames(all.short)=='ccc_a')
x<-which(colnames(all.short)=='group8')
y<-which(colnames(all.short)=='group8level')
z<-which(colnames(all.short)=='trisomy')
z1<-which(colnames(all.short)=='bias')
z2<-which(colnames(all.short)=='dldlevel')
#make file with ID,  and CCC results, as well as group8; gender, age added at end
cccbit<-all.short[,c(1,(w-2):(w+10),x,y,z,z1,z2,2,3)]#2 before ccc_a is GCC and SIDC

cccbit<-filter(cccbit,dldlevel<2) #remove ASD, low IQ etc
w<-which(is.na(cccbit$ccc2_consistent))
cccbit$ccc2_consistent[w]<--1 #we need a count of missing data, so convert NA to -1
consistent.ccc<-table(cccbit$group8,cccbit$ccc2_consistent)

colnames(consistent.ccc)<-c('No data','Inconsistent','Consistent')
consistent.ccc
print('Proportions of non-response to CCC-2')
print(paste('All low bias SCT:',sum(consistent.ccc[1:3,1])/sum(consistent.ccc[1:3,])))
print(paste('All high bias SCT:',sum(consistent.ccc[4:6,1])/sum(consistent.ccc[4:6,])))
print(paste('Twin: no concerns:',sum(consistent.ccc[7,1])/sum(consistent.ccc[7,])))
print(paste('Twin: language concerns:',sum(consistent.ccc[8,1])/sum(consistent.ccc[8,])))

#total responses
print('Overall response rates:')
print(paste('All SCT:',1-sum(consistent.ccc[1:6,1])/sum(consistent.ccc[1:6,])))
print(paste('Twin:',1-sum(consistent.ccc[7:8,1])/sum(consistent.ccc[7:8,])))

```
##Analysis to explore factor affecting response rates
```{r logreg.cccresponse}
all.short2<-all.short
for(i in 1:length(all.short2[,1]))
{
all.short2$response[i]<-ifelse(is.na(all.short2$gcc[i]),0,1)
all.short2$SCT[i]<-ifelse(is.na(all.short2$trisomy[i]),0,1)
}

#Make factor scores for predicting based on severity
model.f5a <- ' f1 =~ wasi_vocab_ss + wdck_jhsn_ss + sent_rep_ss + oromotor_ss_2 
              wasi_vocab_ss ~~ wdck_jhsn_ss'     
fit.mod.E2 <- cfa(model.f5a, data = all.short2,estimator = "ML",missing = "ML")
lbls<-c("Vocabulary", "Woodcock\nJohnson", "Sentence\nRepetition", "Oromotor","Language")

#adjust scores to make suitable for logistic regression
all.short2$lang_severity <- as.numeric( predict(fit.mod.E2)) #factor scores

all.short2$mo_educ<-car::recode(all.short2$mo_educ,"0=1") #recode 0 as 1.

all.short2$mo_educ<-as.factor(all.short2$mo_educ) #make factor for GLM
#run logistic regression
NR1 <- glm(response ~ lang_severity + mo_educ + singlepar + SCT,family=binomial(link='logit'),data=all.short2)
summary(NR1)

```
##Now analyse CCC-2 for 8 groups
```{r ccc.analyse}
#First remove the cases with no response or inconsistent
ccc.data<-filter(cccbit,ccc2_consistent>0)

#create dataframe for summary results
ccc.df<-data.frame(matrix(NA,nrow=8,ncol=26))
ccc.df[,1]<-levels(ccc.data$group8)
ccc.df[,2]<- table(ccc.data$group8)
thiscol<- 1
for (i in 1:12){
  thiscol<-thiscol+2
  thisdat<-ccc.data[,i+1]
  ag <- aggregate(thisdat~ group8, ccc.data, function(x) c(mean = mean(x), se = sd(x)/sqrt(length(x))))
  ccc.df[,(thiscol:(thiscol+1))]<-ag[,2]
}
colnames(ccc.df)<-c('Group','N','GCC.mean','GCC.se','SIDC.mean','SIDC.se','A.mean','A.se','B.mean','B.se','C.mean','C.se','D.mean','D.se',
                    'E.mean','E.se','F.mean','F.se','G.mean','G.se','H.mean','H.se',
                    'I.mean','I.se','J.mean','J.se')
```

```{r cccplot}
#Need data in long form for ggplot2
#set up the long form df with data from scale A
ccc.dflong<-ccc.df[1:8,c(1,2,2,7:8)]
colnames(ccc.dflong)[3:5]<-c('scale','mean','se')
ccc.dflong$scale<-1
mybase<-ccc.dflong

#Now bolt on the other scales
for (j in 2:10){
  #rows to write to in new long df
  startrow<-(j-1)*8+1
  endrow<-(j*8)
  #cols to read from in old df
  startcol<-7+(j-1)*2
  ccc.dflong<-rbind(ccc.dflong,mybase) #just duplicate first 8 rows before overwriting them
  ccc.dflong$scale[startrow:endrow]<-j
  ccc.dflong[startrow:endrow,4:5]<-ccc.df[,startcol:(startcol+1)]
  
}
ccc.dflong$scale<-as.factor(ccc.dflong$scale)
levels(ccc.dflong$scale)<-c('A','B','C','D','E','F','G','H','I','J')
linetypes<-c(1,1,1,2,2,2,1,1)
ccc.dflong$lines<-as.factor(linetypes)
ccc.dflong$plotgroup<-rep(c('XXX','XXY','XYY','XXX','XXY','XYY','twin_typical','twin_concerns'),10)

#Plot the means
ymax <- 12
ymin <- 0
cccplot<-ggplot(ccc.dflong, aes(x=scale, y=mean, colour=plotgroup,group=Group)) +
  geom_line(aes(linetype=lines)) + geom_point(shape=21, fill="white") + 
  ylim(ymin,ymax)
cccplot+geom_errorbar(width=.1, aes(ymin=mean-se, ymax=mean+se))
```
##Manova for CCC-2
Follow https://www.statmethods.net/stats/anova.html

```{r ccc2.manova}
#First just do groups 1-3 on the 10 subscales
ccc.gp3<-filter(ccc.data,group8level<4)
colA<-which(colnames(ccc.gp3)=='ccc_a')

Y <- as.matrix(ccc.gp3[,colA:(colA+9)])
fit.cccsct <- manova(Y ~ ccc.gp3$group8)
summary(fit.cccsct, test="Pillai")

#Now add twin ld group
temp<-filter(ccc.data,group8level==8)
nsct<-nrow(ccc.gp3)
ccc.gp2<-rbind(ccc.gp3,temp)
ccc.gp2$group2<-1
ccc.gp2$group2[1:nsct]<-2
Y <- as.matrix(ccc.gp2[,colA:(colA+9)])
fitccc2 <- manova(Y ~ ccc.gp2$group2)
summary(fitccc2, test="Pillai")

#Now do full 2 way analysis on hi and low bias trisomies
temp1<-filter(ccc.data,group8level<7)
Y6 <- as.matrix(temp1[,colA:(colA+9)])
fitccc6 <- manova(Y6 ~ temp1$trisomy*temp1$bias)
summary(fitccc6, test="Pillai")
#summary.aov(fitccc6) #- if you want to inspect individual language measures

#GCC and SIDC - just do anova
aov.gcc<-aov(temp1$gcc~temp1$trisomy*temp1$bias)
summary(aov.gcc)

aov.scdi<-aov(temp1$scdi~temp1$trisomy*temp1$bias)
summary(aov.scdi)
```

```{r beeswarm.gcc}
png_gcc_bees<-'beeswarm_gcc.png' #name to save png file
png(png_gcc_bees,width=400,height=300)
beeswarm(temp1$gcc~temp1$trisomy*temp1$bias, xlab='Group',ylab='GCC' ,
           pch = 16,cex=.9,col=c(2,2,2,1,1,1),ylim=c(0,120))
  bxplot(temp1$gcc~temp1$trisomy*temp1$bias, probs = 0.5, col = 1,lty=1,add=TRUE) #adds medians for all cases with dotted line
  
    
  mean_TD<-mean(twin.TD$gcc,na.rm=T)
  sd_TD<-sd(twin.TD$gcc,na.rm=T)
  
  up.lim<-mean_TD+sd_TD
  low.lim<-mean_TD-sd_TD
  
  polygon(c(0,0,8,8), c(up.lim, low.lim, low.lim, up.lim),
          col=adjustcolor("yellow",alpha.f=0.3), border = NA)
abline(h=55,lty=3)
dev.off()
```

##Session information
```{r sessinfo}
sessionInfo()
```