---
title: "Logbook for analysis of SCT and twin language data"
author: "Dorothy Bishop"
output: html_document
---

`r Sys.time()`

```{r load_packages, include = FALSE}
#devtools::install_github("rubenarslan/formr")
library(tidyverse)
library(knitr) #for kable - allows nice tables in Word output - but can be temperamental
library(gridExtra)
library(grid)
library(Hmisc)
library(doBy)
library(lme4) #linear model
library(lmerTest) #Adding this extra package provides p-values (if you want them) for your fixed effects.
library(ggridges) #for joyplot
library(car)
require(psych)
library(beeswarm) #particular plot type
library(beanplot) #ditto
library(yarrr) #for pirate plot - another plot type
library(lavaan) #for SEM to extract language factor
library(semPlot) #used with Lavaan
require(formr) #to handle conflicts with 'select' function in dplyr

```


Need to create a main analysis file in which we have a code that corresponds to group.
Have col for trisomy which corresponds to XX, XY, XXX, XXY and XYY: where we know that XX and XY will be twins
Makes sense to use twin column to select just twin1, so just one from each pair
For trisomies, have a col that specifies whether highbias or lowbias
Should be able to use prior code from Newbury et al paper for this

Have a col that determines if meeting criteria for DLD - regardless of whether twin or not.

This can be same criterion as for doppler paper - check this.

For background then need to pull off appropriate columns; simple for sct but for twins need to consider if twinA or twinB.

Given text-based entries, going to be a bit of a nightmare to code.

Also : CCC-2 nonresponse rates - https://www.aapor.org/About-Us/History/Presidential-Addresses/2004-Presidential-Address.aspx

## Step 1
Read in background files: these are very messy with a lot of text entries and some inconsistencies in formatting. Both twins are in one row, so reshaped to make long
Have done ad hoc coding of milestones as follows
Words
1. < 15 months or 'normal'
2. 15-24 mo or 'delayed'
3. > 24 mo or 'very delayed'

Sentences
1. < 36 months or 'normal'
2. 37-48 months or 'delayed'
3. > 4 yr or 'very delayed' or 'not yet'

Walking
1. < 16 months or 'normal'
2. 16-18 months or 'delayed' or 'late'
3. 19 months+ or 'very delayed' etc

Dry
1. < 37 mo or 'normal'
2. 37-59 mo or 'late'
3. 60 + mo or 'very late' or 'not yet'

```{r readbkgfiles, echo=FALSE}
# Read in SCT background file
sct.bkg <- read.csv("background_sct.csv",stringsAsFactors=FALSE)
# Read in twin background file
twin.bkg <- read.csv("background_twin.csv",stringsAsFactors=FALSE)
twin.bkg<-twin.bkg[1:306,] #remove extraneous rows
#reshape twin file so rows for A and B
twinall.bkg<-twin.bkg[,c(1,3,7,11,15)]
colnames(twinall.bkg)<-c('Code','Word_code','Sent_code','Walk_code','Dry_code')
colnames(twin.bkg)[c(5,9,13,17)]<-c('Word_code','Sent_code','Walk_code','Dry_code')
twinall.bkg<-rbind(twinall.bkg,twin.bkg[,c(1,5,9,13,17)])
twinall.bkg$Code[1:306]<-paste0(twinall.bkg$Code[1:306],'A')
twinall.bkg$Code[307:612]<-paste0(twinall.bkg$Code[307:612],'B')



```
## Step 2
Read in latest SCT from redcap.
Do the same for the twins.
Select variables to be used.


```{r readredcap}
redcap.dir <-"~/Dropbox/ERCadvanced/project SCT analysis/Data from Redcap/"
#Use latest version
sct.redcap <- 'SCTDATA_DATA_2018-08-06_0957.csv'
twin.redcap <- 'TwinsData_DATA_2018-08-06_1451.csv' #updated to include ccc2_consistent variable
#also now has pheno_include, which selects individual twins for inclusion
sct.data <- read.csv(paste0(redcap.dir,sct.redcap),stringsAsFactors = FALSE)
twin.data <- read.csv(paste0(redcap.dir,twin.redcap),stringsAsFactors = FALSE)

#fix any columns with discrepant names
w<-which(colnames(twin.data)=='neurodev_diagnosis')
colnames(twin.data)[w] <-'neurodev_diag'

twin.data$dyslexia<-twin.data$dld_rd%%10 #modulus 10 , ie last digit
twin.data$lang_disorder<-round((twin.data$dld_rd-4.5)/10) #first digit is dld code

#add gender info to sct data so it merges properly
sct.data$female<-0
w<-which(sct.data$trisomy==1)
sct.data$female[w]<-1

#----------------------------------------------------------------------------------
```

#Select data for short file
```{r colselect}
keepcols <- c('record_id','female','age_at_test','partial_testing','pass_hearing','wasi_matrices_ss','wasi_block_design_ss','wasi_vocab_ss','wdck_jhsn_ss',
              'sent_rep_ss','oromotor_ss','nonword_rep_ss','nara_acc_ss',      'nara_comp_ss','nara_rate_ss','towre_words_ss','towre_nonwords_ss','phab_pic_ss','phab_digit_ss','srs_t_score','slt','splang_conc','schooling','piq','neurodev_diag','dyslexia','lang_disorder',
              'hyperkinetic_icd_r1','adhd_comb_dsm_r1','adhd_hyp_dsm_r1','adhd_inatt_dsm_r1',
              'conduct_dsm_r1','asd_dsm_r1','autism_icd_r1','srs_t_score',
              'gcc','scdi','ccc_a','ccc_b','ccc_c','ccc_d','ccc_e','ccc_f',
              'ccc_g','ccc_h','ccc_i','ccc_j','ccc2_consistent','mo_educ','fa_educ',
              'nepsy_oromotor_seq_raw')

twin.short <- select(twin.data,keepcols)
sct.short <- select(sct.data,keepcols) #NB 'select' is ambiguous between packages so have to specify dplyr

#----------------------------------------------------------------------------------

#Add columns that are specific to twins or SCTs so all aligned
sct.short$randomtwininclude <- 0 #this specifies child is not a twin but a trisomy
sct.short$zygosity <- NA
twin.short$randomtwininclude <- twin.data$randomtwininclude+1 #twins subdivided
#randomly into 1 and 2 for replication sample
twin.short$zygosity <- twin.data$zygosity
#2 ASD, 3 ASDsib, 4 fail hearing screen (35dB plus mean for better ear), 5 other (rare condition)
#The previous include variable was used for Doppler paper and had more stringent hearing criteria.

sct.short$trisomy <- sct.data$trisomy
sct.short$pre_postnatal_diag <- sct.data$pre_postnatal_diag
sct.short$why_tested <-sct.data$why_tested
twin.short$trisomy <- NA
twin.short$pre_postnatal_diag <- NA
twin.short$why_tested <- NA
twin.short$splang_conc<-twin.data$splang_conc
sct.short$splang_conc<-NA
sct.short$pheno_include<-1
twin.short$pheno_include<-twin.data$pheno_include #this codes reason for exclusion as:


#----------------------------------------------------------------------------------
#Bolt SCT and twin files together
all.short <-rbind(sct.short,twin.short)
#remove case of isochromosome
w<-which(all.short$trisomy==9)
all.short<-all.short[-w,]
all.short<-all.short[all.short$pheno_include==1,]
```
#Check that Ns match those in the protocol
Should have twin groups with N = 143 SCT, 194 twin1 and 194 twin2 (these are randomly assigned twin 1 and 2), 
Numbers are greater than for Newbury et al, as some children did not feature in that study because of lack of DNA.

Twins recruited in relation to splang_conc, which is coded as
0, never
1, preschool only
2, continuing, mild
3, continuing, severe
4, reading concerns only
9, unclear
We will be using this categorisation to subdivide twins; categories 2 and 3 distinguished.

Trisomies - divided according to reason for diagnosis
why tested used to make bias column: coded as: 
0, maternal age
1, medical concerns
2, behavioural concerns
3, neurodevelopmental concerns
4, family history of genetic problems
9, no information

```{r ncheck}
twintab <- table(all.short$randomtwininclude)
names(twintab)<-c('SCT','twin1','twin2')


all.short$bias<-'NA'
w<-which(all.short$randomtwininclude==0)
all.short$bias[w]<-0
w<-c(which(all.short$why_tested==2),which(all.short$why_tested==3))
all.short$bias[w]<-1
scttab <- table(all.short$trisomy,all.short$bias)
rownames(scttab)<-c('XXX','XXY','XYY')
#Show tables
twintab
scttab
rowSums(scttab)

all.short$parentconc<-NA
w<-which(all.short$randomtwininclude>0)
all.short$parentconc[w]<-0
w<-which(all.short$splang_conc%in%c(2,3))
all.short$parentconc[w]<-1
table(all.short$parentconc,all.short$randomtwininclude)
min(sct.data$age_at_test)
max(sct.data$age_at_test)
min(twin.data$age_at_test)
max(twin.data$age_at_test)

```
#Deal with missing data
Check for nonword rep - in some cases need to substitute low score, as unable to attempt task. 
N.B. The process used to extract the language factor can handle missing data, so for measures used in that, we just substitute NA for values > 900.
```{r missingcheck}

all.short$pass_hearing[all.short$pass_hearing==9]<-NA #change 9 to NA for pass_hearing
#NB these include both refusal and equipment failure

#missing data has codes of 996-999 for language tests
w <- which(all.short$nonword_rep_ss>900)
print('Cases with missing nonword rep data: ')
all.short$record_id[w]
#These cases all checked : all SCT cases who either were not tested because v limited spoken language, or who refused spoken tests or had low scores on other language tests. All these cases assigned a scaled score of 3.
all.short$nonword_rep_ss[w] <- 3

#999 is code where child was not tested bcs too low-functioning
w <- which(all.short$wasi_vocab_ss==999)
print('Cases with missing Vocab data (999) reassigned to floor: ')
all.short$record_id[w]
#These assigned SS of 2.33 SD below mean (equivalent to 3 on NEPSY scale)
all.short$wasi_vocab_ss[w] <- 25

w <- which(all.short$wdck_jhsn_ss==999)
print('Cases with missing Woodcock_J data (999) reassigned to floor: ')
all.short$record_id[w]
#These assigned SS of 2.33 SD below mean (equivalent to 3 on NEPSY scale)
all.short$wdck_jhsn_ss[w] <- 55

w <- which(all.short$sent_rep_ss==999)
print('Cases with missing Sent rep data (999) reassigned to floor:: ')
all.short$record_id[w]
#These assigned SS of 2.33 SD below mean (equivalent to 3 on NEPSY scale)
all.short$sent_rep_ss[w] <- 3

w <- which(all.short$oromotor_ss==999)
print('Cases with missing oromotor data (999) reassigned to floor:: ')
all.short$record_id[w]
#These assigned SS of 1 , as this corresponds to floor in this sample
all.short$oromotor_ss[w] <- 1

#Now substitute NA for any remaining > 900
mycols<-colnames(all.short)
mc <-which(mycols=='wasi_matrices_ss')

for (i in mc:(mc+5)){
  w <- which(all.short[,i]>900)
  all.short[w,i]<-NA
  
}
#Parental educ variables, missing is 9
w<-which(all.short$mo_educ==9)
all.short$mo_educ[w]<-NA
w<-which(all.short$fa_educ==9)
all.short$fa_educ[w]<-NA

md <- which(is.na(all.short[,mc:(mc+3)]))
print(paste0(length(md),' missing values from ',nrow(all.short)*4,' datapoints in 4 language tests'))
```
#Compute language factor, using script from Appendix 2
I don't think we will use this, as the focus will be more on individual tests, but it's included for the time being. This is the factor we used for language phenotype in Newbury et al.
Could be useful if we need a general language measure at some point


```{r langfactor}
dolangfactor<-0
if(dolangfactor==1){
model.f5a <- ' f1 =~ wasi_vocab_ss + wdck_jhsn_ss + sent_rep_ss + oromotor_ss 
              wasi_vocab_ss ~~ wdck_jhsn_ss'     
fit.mod.E2 <- cfa(model.f5a, data = all.short,estimator = "ML",missing = "ML")
lbls<-c("Vocabulary", "Woodcock\nJohnson", "Sentence\nRepetition", "Oromotor","Language")
semPaths(fit.mod.E2, "std", title = TRUE, curvePivot = TRUE, edge.label.cex = 1.2,width=10,height=5,nodeLabels=lbls,intercepts = FALSE,sizeMan = 10, sizeLat = 10)
all.short$langfactor <- as.numeric( predict(fit.mod.E2)) #factor scores
beanplot(all.short$langfactor~all.short$randomtwininclude)
#using beanplot as pirateplot was acting funny!
}
```


#Create general neurodevelopmental index, using script from Appendix 3
Our goal is to create a single scale reflecting global level of neurodevelopmental impairment. Data from initial parental telephone interview are available for all children. Data from language testing are available for all but two very low-functioning children, who were unable to attempt our tasks. Data from parental questionnaires (CCC-2 and SRS) and DAWBA DSM5 diagnoses are available for a subset. For SCT cases, questionnaire data were available for 127 out of 143 children, and DAWBA for 89 children. For comparison twin children, questionnaire data were available for 316 out of 388 children, and DAWBA for 276 children. We use all available data for each child to create a scale by adding points as follows:
*History of speech problems = 1
*Current help in mainstream school (support or special class or SLT) =1
*Special school = 2
*Dyslexia (test scores, unless no data , in which case report from parent interview) = 1
*DLD (test scores, unless no data , in which case report from parent interview) = 1
*ADHD (parental report or DAWBA diagnosis) = 1
*Behaviour problems (DAWBA diagnosis of conduct disorder or clear description on interview) = 1
*Autistic features: report from interview of definite diagnosis, or SRS = 90, or DAWBA diagnosis = 2
*Low IQ (PIQ < 70 or refusal/inability to do battery - with exception of reading tests) = 1

```{r makeglobal}
doglobalfactor<-0
if (doglobalfactor==1){ 
  #NB coding for slt is:
#0, never ; 1, preschool only; 2, beyond 4 yr; 3, ongoing; 8, assessed only; 9, no information

# Neurodev diagnosis codes:
# 0 none; others coded as all applicable from list:
#  1 ADHD, 2 APD, 3 ASD, 4 behav, 5 dyscalc, 6 dyslexia, 7 dyspraxia, 8  DLD/SLI/LD, 9 ID/GDD

#Lang dis from test scores; 0, no; 1, subclinical; 2, yes; 8, iq< 70; 9, no test results
#Dyslexia from test scors :0, no; 1, yes; 8, piq< 70; 9, no test results

#lang_concerns from parental report coded as splang_conc:
#0, never; 1, past; 2, continuing mild; 3, continuing severe; 9, unclear
#[for twins we also have code 4 if just concerns re reading; this is ignored here]

#SLT from parent report: 0, never; 1, preschool only; 2, beyond 4 yr; 3, ongoing; 8, assessed only; 9, no information

# School code
#1, mainstream no help; 2, mainstream with help; 3, special class/unit; 4, special school; 5, home schooled; 8, other; 9, dk

all.short$global_neurodev<-0 #Initialise to zero
w<-which(is.na(all.short$srs_t_score)) #Recode NA to 999 for SRS
all.short$srs_t_score[w]<-999

temp<-all.short$global_neurodev
w<-unique(which(all.short$slt==1),which(all.short$slt==8)) #Cases with preschool SLT or assessed by SLT
all.short$global_neurodev[w]<-all.short$global_neurodev[w]+1

#Now code so can add one point for help in mainstream or ongoing SLT or in language unit
w1<-c(which(all.short$schooling==2),which(all.short$schooling==3)) #help in mainstream/lang unit

all.short$global_neurodev[w1]<-all.short$global_neurodev[w1]+1

#add 2 points if attending special school
w<-which(all.short$schooling==4)
all.short$global_neurodev[w]<-all.short$global_neurodev[w]+1

#add 1 point if PIQ < 70 or not completed
w<-which(all.short$piq<70)
w1<-which(all.short$piq>996)
w2<-which(all.short$partial_testing>199) #failed to complete test battery (not because of age)
allw<-unique(w,w1,w2)
all.short$global_neurodev[allw]<-all.short$global_neurodev[allw]+1

## Next bits done in a loop because criteria not captured in a single code
nrows <-nrow(all.short)
for (i in 1:nrows){
  
  # add 1 to code if meets language test criteria for dyslexia OR (if no data) has diagnosis of this 
  # reported on parent interview
  wd<-NA
  temp<-all.short$dyslexia[i] #coding according to test battery, 1 if dyslexic
  if(temp==9){
    wd<-unlist(gregexpr(pattern ='6',toString(all.short$neurodev_diagnosis[i]))) #dyslexia code is 6
    #wd is one if 6 is included in neurodev_diag
  }
  if(length(wd)<1){temp=0}
  if (temp>0){all.short$global_neurodev[i]<-all.short$global_neurodev[i]+1}
  
  #Add 1 to code if evidence of ADHD on parental interview or DAWBA
  w2<-unlist(gregexpr(pattern ='1',toString(all.short$neurodev_diagnosis[i]))) #ADHD code is 1
  if(w2==0){
    w2<-max(all.short$adhd_comb_dsm_r1[i],all.short$adhd_hyp_dsm_r1[i],all.short$adhd_inatt_dsm_r1[i])
  }
  if (w2>0){all.short$global_neurodev[i]<-all.short$global_neurodev[i]+1}
  
  # add 1 to code if meets language test criteria for lang_disorder OR (if no data) has diagnosis of this 
  # reported on parent interview
  
  temp<-all.short$lang_disorder[i] #coding according to test battery, 2 if with poor comp, 1 otherwise
  w1<-temp
  if(w1==2){w1<-1} #just one point added regardless of whether lang_dis code is 1 or 2
  if(temp==9){ #no data on language tests so use parent interview
    w1<-unlist(gregexpr(pattern ='8',toString(all.short$neurodev_diagnosis[i]))) #DLD code is 8
    if(all.short$slt[i]==3){w1<-1} #regardless of diagnosis, ongoing SLT counts as DLD
    if(all.short$splang_conc[i]==3){w1<-1}#also serious language concerns count as DLD
  } 
  if (w1>0){all.short$global_neurodev[i]<-all.short$global_neurodev[i]+w1}
  #NB more severe language problems with poor comprehension get addition of 2 points
  
  # add 1 to code if significant behaviour problems on interview or DAWBA
  
  w1<-unlist(gregexpr(pattern ='4',toString(all.short$neurodev_diagnosis[i]))) #behav problems code is 4
  w2<-all.short$conduct_dsm_r1[i]
  if (is.na(w2)){w2<-0}
  if (max(w1,w2)>0){all.short$global_neurodev[i]<-all.short$global_neurodev[i]+1}
  
  # add 2 to code if ASD on interview or DAWBA or SRS is 90 or more
  
  w1<-unlist(gregexpr(pattern ='3',toString(all.short$neurodev_diagnosis[i]))) #ASD code is 3
  w2<-all.short$asd_dsm_r1[i]
  if(is.na(w2)){w2<-0}
  w3<-0
  
  if(all.short$srs_t_score[i]>89) {w3<-1} #SRS t score 90
  
  if(all.short$srs_t_score[i]>900){w3<-0} 
  if (max(w1,w2,w3)>0){all.short$global_neurodev[i]<-all.short$global_neurodev[i]+2}
  #vertically jittered data created so all points visible on plot
  all.short$global_jittered[i]<-all.short$global_neurodev[i]+.5*runif(1)-.25
}
pirateplot(formula = all.short$global_jittered~ randomtwininclude,
           point.o = .5,
           bar.f.o=.0,
           inf.f.o=.2,
           bean.b.o=.5,
           jitter=.1,
           data = all.short,
           ylab='Global rating',
           ylim=c(0,10),
           main="Distribution of global impairment\n in SCT and Comparison groups")
}
```
##Create 8 groups:
1. XXX-nobias
2. XXY-nobias
3. XYY-nobias
4. XXX-hibias
5. XXY-hibias
6. XYY-hibias
7. twin_noconcern
8. twin_concern
NB as currently defined, not taking into account co-twin status. So a twin_noconcern could have cotwin with concern, ie have family risk.

```{r groupcreate}
all.short$group8<-all.short$trisomy
w<-which(all.short$bias==1)
all.short$group8[w]<-all.short$group8[w]+3 #convert 1 2 3 to 4 5 6
w<-which(all.short$randomtwininclude>0)
all.short$group8[w]<-7
w<-which(all.short$parentconc==1)
all.short$group8[w]<-8
all.short$group8<-as.factor(all.short$group8)
levels(all.short$group8)<-c('XXX.lowbias','XXY.lowbias','XYY.lowbias',
                            'XXX.hibias','XXY.hibias','XYY.hibias',
                            'twin.TD','twin.langconcerns')

#Consider impact of parent education
#0, under 16 (no qualifications)
#1, to 16 (GCSE/Olevel)
#2, to 18 (Alevel)
#3, to 21 (degree)
#4, postgraduate
#9, not known

par.ed <-aggregate(all.short$mo_educ, by=list(all.short$group8),
                   FUN=mean, na.rm=TRUE)
pirateplot(mo_educ~group8,data=all.short)
pirateplot(fa_educ~group8,data=all.short)

```
##CCC-2 analysis
Consider how CCC-2 profiles for SCTs compare with those in our previous paper. Also include twins with or without concerns as comparison group.  Show both subscales and the GCC and SIDC.
Just use twin1 for this (regardless of language status)

```{r ccc2}
all.vshort<-filter(all.short,randomtwininclude<2) #remove twin2
w<-which(colnames(all.vshort)=='ccc_a')
x<-which(colnames(all.vshort)=='group8')
cccbit<-all.vshort[,c(1,(w-2):(w+10),x)]#2 before ccc_a is GCC and SIDC
w<-which(is.na(cccbit$ccc2_consistent))
cccbit$ccc2_consistent[w]<--1 #we need a count of missing data, so convert NA to -1
consistent.ccc<-table(cccbit$group8,cccbit$ccc2_consistent)

colnames(consistent.ccc)<-c('No data','Inconsistent','Consistent')
consistent.ccc
print('Proportions of non-response to CCC-2')
print(paste('All low bias SCT:',sum(consistent.ccc[1:3,1])/sum(consistent.ccc[1:3,])))
print(paste('All high bias SCT:',sum(consistent.ccc[4:6,1])/sum(consistent.ccc[4:6,])))
print(paste('Twin: no concerns:',sum(consistent.ccc[7,1])/sum(consistent.ccc[7,])))
print(paste('Twin: language concerns:',sum(consistent.ccc[8,1])/sum(consistent.ccc[8,])))

```
##Now analyse CCC-2 for 8 groups

```{r ccc.analyse}
#First remove the cases with no response or inconsistent
ccc.data<-filter(cccbit,ccc2_consistent>0)
#create dataframe for results
ccc.df<-data.frame(matrix(NA,nrow=8,ncol=30))
ccc.df[,1]<-levels(ccc.data$group8)
ccc.df[,2]<- table(ccc.data$group8)
thiscol<- 1
for (i in 1:12){
  thiscol<-thiscol+2
  thisdat<-ccc.data[,i+1]
  ag <- aggregate(thisdat~ group8, ccc.data, function(x) c(mean = mean(x), se = sd(x)/sqrt(length(x))))
  ccc.df[,(thiscol:(thiscol+1))]<-ag[,2]
}
colnames(ccc.df)<-c('Group','N','GCC.mean','GCC.se','SIDC.mean','SIDC.se','A.mean','A.se','B.mean','B.se','C.mean','C.se','D.mean','D.se',
                    'E.mean','E.se','F.mean','F.se','G.mean','G.se','H.mean','H.se',
                    'I.mean','I.se','J.mean','J.se')
```

```{r cccplot}
#Need data in long form for ggplot2
#set up the long form df with data from scale A
ccc.dflong<-ccc.df[1:8,c(1,2,2,7:8)]
colnames(ccc.dflong)[3:5]<-c('scale','mean','se')
ccc.dflong$scale<-1
mybase<-ccc.dflong

#Now bolt on the other scales
for (j in 2:10){
  #rows to write to in new long df
  startrow<-(j-1)*8+1
  endrow<-(j*8)
  #cols to read from in old df
  startcol<-7+(j-1)*2
  ccc.dflong<-rbind(ccc.dflong,mybase) #just duplicate first 8 rows before overwriting them
  ccc.dflong$scale[startrow:endrow]<-j
  ccc.dflong[startrow:endrow,4:5]<-ccc.df[,startcol:(startcol+1)]
  
}
ccc.dflong$scale<-as.factor(ccc.dflong$scale)
levels(ccc.dflong$scale)<-c('A','B','C','D','E','F','G','H','I','J')
linetypes<-c(1,1,1,2,2,2,1,1)
ccc.dflong$lines<-as.factor(linetypes)
ccc.dflong$plotgroup<-rep(c('XXX','XXY','XYY','XXX','XXY','XYY','twin_typical','twin_concerns'),10)

#Plot the means
ymax <- 12
ymin <- 0
cccplot<-ggplot(ccc.dflong, aes(x=scale, y=mean, colour=plotgroup,group=Group)) +
  geom_line(aes(linetype=lines)) + geom_point(shape=21, fill="white") + 
  ylim(ymin,ymax)
cccplot+geom_errorbar(width=.1, aes(ymin=mean-se, ymax=mean+se))
```
##Look at language tests in the same way
Profile plot useful for overall indication

```{r langmeasures}


langcogcols<-c("wasi_matrices_ss" ,"wasi_block_design_ss", "wasi_vocab_ss" ,
               "wdck_jhsn_ss" , "sent_rep_ss", "oromotor_ss" , "nonword_rep_ss", 
               "nara_acc_ss" ,"nara_comp_ss","nara_rate_ss" ,"towre_words_ss",
               "towre_nonwords_ss","phab_pic_ss","phab_digit_ss","group8"  )

langcog<-dplyr::select(all.vshort,langcogcols)
#Make shorter names for plotting
colnames(langcog)<-c('Matrices','Blocks','Vocab','WJ Comp','SentRep','Oromotor','NwdRep',
                     'ReadAcc','ReadComp','ReadRate','TOWREwd','TOWREnwd',
                     'PicName','DigitName','Group')
#convert missing data to NA
numcols<-length(langcogcols)
for (i in 1:(numcols-1)){
  w<-which(langcog[,i]>900)
  langcog[w,i]<-NA
}
#convert all variables to same scale: mean 100 and SD 15
for (i in 1:3){
  oldmean<-50
  oldsd<-10
  langcog[,i]<- 100+15*(langcog[,i]-oldmean)/oldsd
}
for (i in 5:7){
  oldmean<-10
  oldsd<-3
  langcog[,i]<- 100+15*(langcog[,i]-oldmean)/oldsd
}
langcog$record_id<-all.vshort$record_id

langcols<-c("Vocab","WJ Comp","SentRep","NwdRep" )
langcog$N.lowlang<-0
langcog$N.na.lang<-0
for (j in 1:length(langcols)){
  thiscol<-match(langcols[j],names(langcog))
  w<-which(langcog[,thiscol]<85)
  if (length(w)>0){
  langcog$N.lowlang[w]<-langcog$N.lowlang[w]+1
  }
  w<-which(is.na(langcog[,thiscol]))
   if (length(w)>0){
  langcog$N.na.lang[w]<-langcog$N.na.lang[w]+1
   }
}
langcog$DLD<-0
langcog$DLD[langcog$N.lowlang>1]<-1
langcog$piq<-all.vshort$piq
langcog$DLD[langcog$piq<70]<-2
langcog$DLD[langcog$N.na.lang>0]<-9
dldtab<-table(langcog$Group,langcog$DLD)
colnames(dldtab)<-c('None','DLD','LowIQ','missing')
dldtab
```

This reveals big problem with oromotor - presumably because it does not have any variance at high end. For the time being will just add 15 to the SS, which aligns mean for TD twin group - but  need to consider this again.


#Go direct to creation of longform means file
```{r makelonglangmeans}
#start by adding fudge factor to oromotor (see above)
langcog[,6]<-langcog[,6]+15
longlangmeans<-ccc.dflong #we will overwrite this dataframe
longlangmeans$scale<-levels(longlangmeans$scale)[longlangmeans$scale] 
for (i in 1:(numcols-1)){
  startrow<-1+8*(i-1)
  endrow<-8*i
  thisdat<-langcog[,i]
  longlangmeans[startrow:endrow,c(1,6,7)]<-longlangmeans[1:8,c(1,6,7)]#needed bcs more vars than in CCC
  
  ag <- aggregate(thisdat~ Group, langcog, function(x) N = length(x))
  longlangmeans[startrow:endrow,2]<-ag[,2]
  longlangmeans[startrow:endrow,3]<-colnames(langcog)[i]
  ag <- aggregate(thisdat~ Group, langcog, function(x) mean = mean(x))
  longlangmeans[startrow:endrow,4]<-ag[,2]
  ag <- aggregate(thisdat~ Group, langcog, function(x) se = sd(x)/sqrt(length(x)))
  longlangmeans[startrow:endrow,5]<-ag[,2]
  
}
longlangmeans$scale<-as.factor(longlangmeans$scale)

```
##Plot language measures
Despite my renorming, oromotor looks low.
Check raw vs ss in both twin and sct
```{r oromotor}
#added nepsy_oromotor_seq_raw to list of variables so we can look at it
#focus just on those in same age range: nb SCT includes both older and younger kids

bit<-filter(all.vshort,age_at_test>71)
bit<-filter(bit,age_at_test<145)
pirateplot(age_at_test~group8,data=bit)
pirateplot(nepsy_oromotor_seq_raw~group8,data=bit)
pirateplot(oromotor_ss~group8,data=bit)

```

```{r langplots}
#Plot the means
ymax <- 115
ymin <- 60
langplot<-ggplot(longlangmeans[1:56,], aes(x=scale, y=mean, colour=plotgroup,group=Group)) +
  geom_line(aes(linetype=lines)) + geom_point(shape=21, fill="white") + 
  ylim(ymin,ymax)
langplot+geom_errorbar(width=.1, aes(ymin=mean-se, ymax=mean+se))

#Repeat for reading data (nb fewer cases)
readplot<-ggplot(longlangmeans[57:112,], aes(x=scale, y=mean, colour=plotgroup,group=Group)) +
  geom_line(aes(linetype=lines)) + geom_point(shape=21, fill="white") + 
  ylim(ymin,ymax)
readplot+geom_errorbar(width=.1, aes(ymin=mean-se, ymax=mean+se))

```

Thoughts on plots: reading seems far less impaired than language tests.
Twins with concerns doing fine on TOWRE and pretty good on Neale.
For SCTs need to check if this is age-related - i.e. we have included more younger children in the language tests than in the reading tests.

Also qu of whether should renorm everything to the twin typical group. But problem as they have higher parental ed I think. Would be worth doing postcode check.

Qu of whether better reading is all down to changes in curriculum since tests were normed. There is a consistent gap between the two twin groups- just that everyone doing well.

```{r dld_code}
#Create code for DLD; if 2 of 4 tests (NWRep, SentRep, Vocab and WJComp) < 80 and PIQ>70

```

```{r wasi}
mycollist<-c('red','green','blue','pink','purple','darkblue','grey','black')
plot(all.vshort$wasi_block_design_ss,all.vshort$wasi_vocab_ss,col=mycollist[all.vshort$group8])
abline(coef=c(0,1))

all.vshort$PV<-all.vshort$wasi_block_design_ss-all.vshort$wasi_vocab_ss
 ag <- aggregate(all.vshort$PV~ group8, all.vshort, function(x) c(N=length(x),mean = mean(x), sd = sd(x)))

#just look at lowbias trisomies plus controls
all.short.lorisk<-filter(all.vshort,group8%in%levels(all.vshort$group8)[c(1,2,3,7)])
plot(all.short.lorisk$wasi_block_design_ss,all.short.lorisk$wasi_vocab_ss,col=mycollist[all.short.lorisk$group8])
abline(coef=c(0,1))

```
##Preliminary look at background variables
Estimate of early language milestones.
Would also be of interest to see how diagnosis relates to language profile

```{r langbackground}
#as gender is important here, we'll make a 10-group code!
all.vshort$group10<-all.vshort$group8
levels(all.vshort$group10)<-c(levels(all.vshort$group10)[1:6],'TD.male','TD.female','LD.male','LD.female')
w1<-which(all.vshort$group8=='twin.TD')
w2<-which(all.vshort$group8=='twin.langconcerns')
w3<-which(all.vshort$female==0)
w4<-which(all.vshort$female==1)
w<-intersect(w1,w3)
all.vshort$group10[w]<-levels(all.vshort$group10)[7]
w<-intersect(w1,w4)
all.vshort$group10[w]<-levels(all.vshort$group10)[8]
w<-intersect(w2,w3)
all.vshort$group10[w]<-levels(all.vshort$group10)[9]
w<-intersect(w2,w4)
all.vshort$group10[w]<-levels(all.vshort$group10)[10]

#add 4 columns to all.vshort for the milestone codes

all.vshort$Words_code<-NA
all.vshort$Sent_code<-NA
all.vshort$Walk_code<-NA
all.vshort$Dry_code<-NA
lastcol<-dim(all.vshort)[2]
col1<-lastcol-3
col2<-lastcol
#add data for twins
tstart<-min(which(all.vshort$randomtwininclude>0)) #start row for twins
for (j in tstart:nrow(all.vshort)){
  w<-which(twinall.bkg$Code==all.vshort$record_id[j])
  all.vshort[j,col1:col2]<-twinall.bkg[w,2:5]
}
#add data for SCTs
tend<-tstart-2 #end row for SCTs (nb last SCT (370) ? not on background file?)
for (j in 1:tend){
  w<-which(sct.bkg$Code==all.vshort$record_id[j])
  all.vshort[j,col1:col2]<-sct.bkg[w,c(3,5,7,9)]
}
t1<-table(all.vshort$group10,all.vshort$Words_code)
colnames(t1)<-c('1stwords_normal','1stwords_late','1stwords_v.late')
t2<-table(all.vshort$group10,all.vshort$Sent_code)
colnames(t2)<-c('Sentences_normal','Sentences_late','Sentences_v.late')
t3<-table(all.vshort$group10,all.vshort$Walk_code)
colnames(t3)<-c('Walk_normal','Walk_late','Walk_v.late')

t4<-table(all.vshort$group10,all.vshort$Dry_code)
colnames(t4)<-c('Dry_normal','Dry_late','Dry_v.late')

prop.table(t1,1) #gives proportions by row (index 1)
prop.table(t2,1)
prop.table(t3,1)
prop.table(t4,1)
```
##Session information
```{r sessinfo}
sessionInfo()
``